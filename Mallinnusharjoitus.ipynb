{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Created by Petteri Nevavuori <<petteri.nevavuori@gmail.com>>*\n",
    "\n",
    "---\n",
    "\n",
    "**CHIO & FREEMAN: MACHINE LEARNING & SECURITY (2018)** <br>\n",
    "*<small>Otsikot kirjan mukaan, muutoin suomeksi.</small>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Sisällysluettelo<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Mallinnusharjoitus\" data-toc-modified-id=\"Mallinnusharjoitus-1\">Mallinnusharjoitus</a></span><ul class=\"toc-item\"><li><span><a href=\"#Datajoukosta\" data-toc-modified-id=\"Datajoukosta-1.1\">Datajoukosta</a></span></li><li><span><a href=\"#Mallinnuksesta\" data-toc-modified-id=\"Mallinnuksesta-1.2\">Mallinnuksesta</a></span><ul class=\"toc-item\"><li><span><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-1.2.1\">LSTM</a></span></li><li><span><a href=\"#Datan-käsittely\" data-toc-modified-id=\"Datan-käsittely-1.2.2\">Datan käsittely</a></span></li></ul></li><li><span><a href=\"#Datan-esikäsittely\" data-toc-modified-id=\"Datan-esikäsittely-1.3\">Datan esikäsittely</a></span><ul class=\"toc-item\"><li><span><a href=\"#Datan-lataus\" data-toc-modified-id=\"Datan-lataus-1.3.1\">Datan lataus</a></span></li><li><span><a href=\"#Datan-muokkaus\" data-toc-modified-id=\"Datan-muokkaus-1.3.2\">Datan muokkaus</a></span></li><li><span><a href=\"#Nimiöity-datajoukko\" data-toc-modified-id=\"Nimiöity-datajoukko-1.3.3\">Nimiöity datajoukko</a></span></li><li><span><a href=\"#Data-tensoreiksi\" data-toc-modified-id=\"Data-tensoreiksi-1.3.4\">Data tensoreiksi</a></span></li></ul></li><li><span><a href=\"#Mallin-rakentaminen\" data-toc-modified-id=\"Mallin-rakentaminen-1.4\">Mallin rakentaminen</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset-luokka\" data-toc-modified-id=\"Dataset-luokka-1.4.1\">Dataset-luokka</a></span></li><li><span><a href=\"#LSTM-luokka\" data-toc-modified-id=\"LSTM-luokka-1.4.2\">LSTM-luokka</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mallinnusharjoitus\n",
    "\n",
    "Tässä Notebookissa käydään läpi poikkeamien havaintomallin koulutus harjoitusmielessä. Ensin esitellään data, minkä jälkeen esitellään koulutettava malli perusajatuksineen ja tämän jälkeen koulutetaan itse malli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datajoukosta\n",
    "\n",
    "Datajoukkona toimii [ADFA-LD](https://www.unsw.adfa.edu.au/unsw-canberra-cyber/cybersecurity/ADFA-IDS-Datasets/), joka on vuonna 2012 alunperin koottu käyttöjärjestelmän toimintaan liittyvien poikkeamien havaintomallien koulutusta varten. Datajoukko koostuu tyystin järjestelmäkutsuista, jotka on enkoodattu numeeriseen muotoon. Yksi numero vastaa yhtä Ubuntun järjestelmäkutsuista. Data on kerätty Ubuntu-käyttöjärjestelmän versiosta 11.04 käyttämällä `auditd`-palvelua. Tärkein palvelun keräämä tieto on `syscall`-tietue, joka ADFA-LD:ssä on kerätty sekvensseinä. Raakamuodossaan `auditd`:n keräämä data näyttää seuraavalta:\n",
    "\n",
    "    =====================================================================\n",
    "    #  date         time        syscall pid     comm        auid    event\n",
    "    =====================================================================\n",
    "    1. 12/04/2018   14:14:35    257     2309    DOM Worker  1000    82\n",
    "    2. 12/04/2018   14:16:58    257     2309    DOM Worker  1000    83\n",
    "    3. 12/04/2018   14:21:53    257     2309    DOM Worker  1000    90\n",
    "    4. 12/04/2018   14:26:58    257     2309    DOM Worker  1000    91\n",
    "    5. 12/04/2018   14:29:28    257     2309    DOM Worker  1000    92\n",
    "    6. 12/04/2018   14:31:58    257     2309    DOM Worker  1000    93\n",
    "    7. 12/04/2018   14:36:58    257     2309    DOM Worker  1000    94\n",
    "    8. 12/04/2018   14:40:00    257     2309    DOM Worker  1000    95\n",
    "    9. 12/04/2018   14:41:58    257     2309    DOM Worker  1000    96\n",
    "    ...\n",
    "\n",
    "Datajoukossa data on seuraavassa muodossa:\n",
    "\n",
    "    54 175 120 175 175 3 175 175 120 175 120 175 120 175 175 120 175 3 3 3 \n",
    "    175 120 175 175 175 7 3 3 175 120 175 7 175 7 119 174 54 3 3 175 175 3 \n",
    "    120 175 175 120 175 120 120 175 175 54 140 3 175 120 175 175 175 175 ...\n",
    "Datajoukko on jaoteltu siten, että siinä on erilliset datajoukot normaalin perustilan oppimiselle, hyökkäyksille ja validointitarkoitukseen kerätylle normaalille datalle. Datajoukko on alunperin muodostettu siten, että siitä muodostetaan uniikkeja $n$-grammeja ja näiden avulla pyritään tunnistamaan perustilasta poikkeava toiminta. Se ei siis ole mitenkään ajallisesti riippuvaisessa muodossa, vaan koostuu yksittäisistä useasta järjestelmäkutsusta muodostuvista jäljistä (*trace*). Mallin koulutuksen päämääränä on tällöin oppia normaali perustila käyttämällä koulutukseen haitattomia jälkiä."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mallinnuksesta\n",
    "\n",
    "Koska tavoitteena on oppia erottamaan poikkeava toiminta normaalista, on kyseessä yksinkertaistetusti binääriluokitteluongelma. Vaikka datajoukon jäljet ovatkin annettu toisistaan riippumattomina, ovat jälkien sisäiset järjestelmäkutsut vahvasti sekvenssisiä. \n",
    "\n",
    "### LSTM\n",
    "\n",
    "Tästä syystä LSTM-malli voisi soveltua luokittimeksi siten, lukisi jäljet ikäänkuin rihmana tarkastellen aina muutamaa järjestelmäkutsua kerrallaan. Tärkeää kuitenkin on, ettei jälkiä sekoiteta keskenään ja mallille anneta valheellista käsitystä jälkien välisistä yhteyksistä. Koska jäljet koostuvat monista järjestelmäkutsuista (100+), voisi pinottu LSTM olla vain yksitasoista vastaavaa parempi - näin malli voisi paremmin oppia käsiteltävän sekvenssipituuden ylittäviä ajallisia piirteitä.\n",
    "\n",
    "Vaikka LSTM-malli ei itsessään ole ns. tilaa oppiva, kuten vaikkapa RBM, testataan tässä harjoituksessa sitä, että voidaanko kyseistä mallia käyttää poikkeamien havaitsemiseen. Tätä tavoitellaan siten, että malli opetetaan tuottamaan ADFA-datajoukon koulutusosajoukolla luokittelutulokseksi arvo `1`. Koulutuksen jälkeen mallia arvioidaan validointi- ja hyökkäysjoukoilla. Arvioinnin tavoitteena on selvittää, tekeekö malli eroa hyökkäysekvenssien ja normaalien sekvenssien suhteen.\n",
    "\n",
    "### Datan käsittely\n",
    "\n",
    "Vaikkakin data on näennäisen numeerista, on kyseessä kuitenkin ennemmin lista kategorisia kuin jatkuvia arvoja. Tällöin data olisi syötettävä ennemmin harvana matriisina siten, että yksi sarake vastaa yhtä järjestelmäkutsua ja yhdellä sarakkeella esiintyy vain yksi kutsu. Tällöin data näyttäisi listan sijasta seuraavankaltaiselta:\n",
    "    \n",
    "    ==================================\n",
    "    #. 1 2 3 4 5 6 ... 300 301 302 ...\n",
    "    ==================================\n",
    "    1. 0 0 1 0 0 0 ... 0   0   0   ...\n",
    "    2. 0 0 1 0 0 0 ... 0   0   0   ...\n",
    "    3. 0 0 1 0 0 0 ... 0   0   0   ...\n",
    "    4. 0 1 0 0 0 0 ... 0   0   0   ...\n",
    "    5. 0 0 0 0 0 0 ... 0   1   0   ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datan esikäsittely\n",
    "\n",
    "Ylätason esittelyn jälkeen on parempi siirtyä suoraan toteutukseen ja selittää tekemistä auki matkan varrella. Ensin aloitetaan datan käsittelyllä, minkä jälkeen jatketaan mallin ja siihen liittyvän datajoukkojen käsittelijöiden rakentamisella. Lopuksi malli koulututetaan ja sen tuloksia vertaillaan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datan lataus\n",
    "\n",
    "Aloitetaan datan käsittelyosio määrittämällä polut oikeisiin kansioihin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ADFA_LD_DIR = os.path.join(os.getcwd(),'datasets','ADFA-LD')\n",
    "TRAINING_DIR = os.path.join(ADFA_LD_DIR,'Training_Data_Master')\n",
    "ATTACK_DIR = os.path.join(ADFA_LD_DIR,'Attack_Data_Master')\n",
    "VALIDATION_DIR = os.path.join(ADFA_LD_DIR,'Validation_Data_Master')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kurkistetaanpa kansioiden sisältöihin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-kansion sisältöä:\n",
      "  UTD-0557.txt, UTD-0396.txt, UTD-0622.txt, UTD-0813.txt, UTD-0111.txt, UTD-0510.txt, ...\n",
      "Attack-kansion sisältöä:\n",
      "  Web_Shell_2, Adduser_7, Web_Shell_5, Java_Meterpreter_8, Meterpreter_3, Java_Meterpreter_4, ...\n",
      "Validation-kansion sisältöä:\n",
      "  UVD-1353.txt, UVD-0058.txt, UVD-3975.txt, UVD-2774.txt, UVD-2282.txt, UVD-1079.txt, ...\n"
     ]
    }
   ],
   "source": [
    "print('Training-kansion sisältöä:')\n",
    "print(f'  {\", \".join(os.listdir(TRAINING_DIR)[:6])}, ...')\n",
    "\n",
    "print('Attack-kansion sisältöä:')\n",
    "print(f'  {\", \".join(os.listdir(ATTACK_DIR)[:6])}, ...')\n",
    "\n",
    "print('Validation-kansion sisältöä:')\n",
    "print(f'  {\", \".join(os.listdir(VALIDATION_DIR)[:6])}, ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training- ja Validation-kansiot sisältävät suoraan tekstitiedostoja, jotka itsessään ovat järjestelmäkutsuja sisältäviä jälkiä. Katsotaanpa tarkemmin vielä Attack-kansion alikansioita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack-kansion alikansioiden sisältöä:\n",
      "  UAD-WS2-4605.txt, UAD-WS2-1613.txt, UAD-WS2-4568.txt, ...\n",
      "  UAD-Adduser-7-1371.txt, UAD-Adduser-7-2311.txt, UAD-Adduser-7-18802.txt, ...\n",
      "  UAD-WS5-5029.txt, UAD-WS5-961.txt, UAD-WS5-2462.txt, ...\n"
     ]
    }
   ],
   "source": [
    "print('Attack-kansion alikansioiden sisältöä:')\n",
    "print(f'  {\", \".join(os.listdir(os.path.join(ATTACK_DIR,os.listdir(ATTACK_DIR)[0]))[:3])}, ...')\n",
    "print(f'  {\", \".join(os.listdir(os.path.join(ATTACK_DIR,os.listdir(ATTACK_DIR)[1]))[:3])}, ...')\n",
    "print(f'  {\", \".join(os.listdir(os.path.join(ATTACK_DIR,os.listdir(ATTACK_DIR)[2]))[:3])}, ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyökkäystyypit on siis jaoteltu omiin kansioihinsa. Kokeillaanpa seuraavaksi yhden järjestelmäkutsuja sisältävän tiedoston käsittelyä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ladatun tiedoston\n",
      "  rivimäärä: 1\n",
      "  sisällön tyyppi: <class 'str'>\n",
      "  muutama järjestelmäkutsua: 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 3 4 \n"
     ]
    }
   ],
   "source": [
    "content=[]\n",
    "with open(os.path.join(TRAINING_DIR,os.listdir(TRAINING_DIR)[0])) as file:\n",
    "    for line in file.readlines():\n",
    "        content.append(line)\n",
    "\n",
    "print(f'Ladatun tiedoston')\n",
    "print(f'  rivimäärä: {len(content)}')\n",
    "print(f'  sisällön tyyppi: {type(content[0])}')\n",
    "print(f'  muutama järjestelmäkutsua: {content[0][:60]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eli kutsujen numeeriset arvot on parsittava. Tehdäänpä vielä se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiedoston sekvenssin\n",
      "  pituus: 1986\n",
      "  sisällön tyyppi: <class 'int'>\n",
      "  muutama järjestelmäkutsua: [3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(TRAINING_DIR,os.listdir(TRAINING_DIR)[0])) as file:\n",
    "    for line in file.readlines():\n",
    "        sequence = [int(syscall) for syscall in line.split()]\n",
    "        break\n",
    "\n",
    "print(f'Tiedoston sekvenssin')\n",
    "print(f'  pituus: {len(sequence)}')\n",
    "print(f'  sisällön tyyppi: {type(sequence[0])}')\n",
    "print(f'  muutama järjestelmäkutsua: {sequence[:20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ladataanpa seuraavaksi omiin muuttujiinsa kaikki data. Training- ja Validation-datat voidaan ladata suoraan listoina. Vaikka hyökkäystyypit ovatkin lähtökohtaisesti eroteltuina, nekin imaistaan vain yhdeksi suureksi listaksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luettiin 833 Training-datan jälkeä.\n",
      "Luettiin 4372 Validation-datan jälkeä.\n",
      "Luettiin 746 Attack-datan jälkeä.\n"
     ]
    }
   ],
   "source": [
    "training_sequences = []\n",
    "validation_sequences = []\n",
    "attack_sequences = []\n",
    "\n",
    "for file_name in os.listdir(TRAINING_DIR):\n",
    "    with open(os.path.join(TRAINING_DIR,file_name)) as file:\n",
    "        for line in file.readlines():\n",
    "            training_sequences.append([int(syscall) for syscall in line.split()])\n",
    "            break\n",
    "            \n",
    "print(f'Luettiin {len(training_sequences)} Training-datan jälkeä.')\n",
    "\n",
    "for file_name in os.listdir(VALIDATION_DIR):\n",
    "    with open(os.path.join(VALIDATION_DIR,file_name)) as file:\n",
    "        for line in file.readlines():\n",
    "            validation_sequences.append([int(syscall) for syscall in line.split()])\n",
    "            break\n",
    "            \n",
    "print(f'Luettiin {len(validation_sequences)} Validation-datan jälkeä.')\n",
    "\n",
    "for folder in os.listdir(ATTACK_DIR):\n",
    "    attack_dir = os.path.join(ATTACK_DIR,folder)\n",
    "    for file_name in os.listdir(attack_dir):\n",
    "        with open(os.path.join(attack_dir,file_name)) as file:\n",
    "            for line in file.readlines():\n",
    "                attack_sequences.append([int(syscall) for syscall in line.split()])\n",
    "                break\n",
    "                \n",
    "print(f'Luettiin {len(attack_sequences)} Attack-datan jälkeä.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datan muokkaus\n",
    "\n",
    "Data ei kuitenkaan ole vielä tällaisenaan käyttökelpoista. Koska tavoitteena on muodostaa kategorinen harva matriisi, on ensin saata tietoa koko datajoukon uniikeista järjestelmäkutsuista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datajoukossa on 175 uniikkia järjestelmäkutsua.\n"
     ]
    }
   ],
   "source": [
    "unique_syscalls = set()\n",
    "\n",
    "for sequence in training_sequences:\n",
    "    for syscall in sequence:\n",
    "        unique_syscalls.add(syscall)\n",
    "\n",
    "for sequence in validation_sequences:\n",
    "    for syscall in sequence:\n",
    "        unique_syscalls.add(syscall)\n",
    "\n",
    "for sequence in attack_sequences:\n",
    "    for syscall in sequence:\n",
    "        unique_syscalls.add(syscall)\n",
    "            \n",
    "print(f'Datajoukossa on {len(unique_syscalls)} uniikkia järjestelmäkutsua.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tehdään uniikeista kutsuista vielä `dictionary`, jossa uniikit arvot yhdistetään juoksevaan numerointiin. Tätä voidaan käyttää suoraan harvan matriisin tekoon siten, että sarakkeet saadaan menemään oikein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jotain järjestelmäkutsu-numero-pareja:\n",
      "  Syscall 1\tNumero 0\n",
      "  Syscall 3\tNumero 1\n",
      "  Syscall 4\tNumero 2\n",
      "  Syscall 5\tNumero 3\n",
      "  Syscall 6\tNumero 4\n",
      "  Syscall 7\tNumero 5\n",
      "  Syscall 8\tNumero 6\n",
      "  Syscall 9\tNumero 7\n",
      "  Syscall 10\tNumero 8\n",
      "  Syscall 11\tNumero 9\n",
      "  ...\t\t...\n"
     ]
    }
   ],
   "source": [
    "syscalls_dict = {syscall:number for number,syscall in enumerate(unique_syscalls)}\n",
    "\n",
    "print('Jotain järjestelmäkutsu-numero-pareja:')\n",
    "for i,item in enumerate(syscalls_dict.items()):\n",
    "    print(f'  Syscall {item[0]}\\tNumero {item[1]}')\n",
    "    if i == 9:\n",
    "        print(f'  ...\\t\\t...')\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seuraavaksi on vuorossa jokaisen sekvenssin muuntaminen harvaksi matriisiksi. Tarkastellaan ensin yksittäistä sekvenssiä ja sen muuntamista hyödyntämällä suoraan edellisen koodiblokin viimeistä `sequence` muuttujaa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "syscalls = np.zeros(shape=(len(sequence),len(unique_syscalls)),dtype=int)\n",
    "for i, syscall in enumerate(sequence):\n",
    "    syscalls[i,syscalls_dict[syscall]] = 1\n",
    "syscalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tehdään sama seuraavaksi jokaiselle sekvenssille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sequence in enumerate(training_sequences):\n",
    "    syscalls = np.zeros(shape=(len(sequence),len(unique_syscalls)),dtype=int)\n",
    "    for j, syscall in enumerate(sequence):\n",
    "        syscalls[j,syscalls_dict[syscall]] = 1\n",
    "    training_sequences[i] = syscalls\n",
    "    \n",
    "for i, sequence in enumerate(validation_sequences):\n",
    "    syscalls = np.zeros(shape=(len(sequence),len(unique_syscalls)),dtype=int)\n",
    "    for j, syscall in enumerate(sequence):\n",
    "        syscalls[j,syscalls_dict[syscall]] = 1\n",
    "    validation_sequences[i] = syscalls\n",
    "    \n",
    "for i, sequence in enumerate(attack_sequences):\n",
    "    syscalls = np.zeros(shape=(len(sequence),len(unique_syscalls)),dtype=int)\n",
    "    for j, syscall in enumerate(sequence):\n",
    "        syscalls[j,syscalls_dict[syscall]] = 1\n",
    "    attack_sequences[i] = syscalls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kurkataanpa vielä jokaisen osajoukon sisälle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-joukon ensimmäinen jälki\n",
      "  koko:(1986, 175)\n",
      "Validation-joukon ensimmäinen jälki\n",
      "  koko:(343, 175)\n",
      "Attack-joukon ensimmäinen jälki\n",
      "  koko:(334, 175)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training-joukon ensimmäinen jälki')\n",
    "print(f'  koko:{training_sequences[0].shape}')\n",
    "\n",
    "print(f'Validation-joukon ensimmäinen jälki')\n",
    "print(f'  koko:{validation_sequences[0].shape}')\n",
    "\n",
    "print(f'Attack-joukon ensimmäinen jälki')\n",
    "print(f'  koko:{attack_sequences[0].shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nimiöity datajoukko\n",
    "\n",
    "Lopuksi kullekin datajoukolle annetaan oikea leima. Luokka `1` tarkoittaa normaalia, `0` poikkeamaa. Näin malli oppii tuottamaan mahdollisimman tarkan tuloksen normaalitilalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nimiöidyn Training-joukon ensimmäinen jälki\n",
      "  koko:(1986, 175)\n",
      "  luokka:1\n",
      "Nimiöidyn Validation-joukon ensimmäinen jälki\n",
      "  koko:(343, 175)\n",
      "  luokka:1\n",
      "Nimiöidyn Attack-joukon ensimmäinen jälki\n",
      "  koko:(334, 175)\n",
      "  luokka:0\n"
     ]
    }
   ],
   "source": [
    "training_sequences_labels = np.ones(shape=(len(training_sequences),),dtype=int).tolist()\n",
    "validation_sequences_labels = np.ones(shape=(len(validation_sequences),),dtype=int).tolist()\n",
    "attack_sequences_labels = np.zeros(shape=(len(attack_sequences),),dtype=int).tolist()\n",
    "\n",
    "training_sequences_labeled = [training_sequences,training_sequences_labels]\n",
    "validation_sequences_labeled = [validation_sequences, validation_sequences_labels]\n",
    "attack_sequences_labeled = [attack_sequences, attack_sequences_labels]\n",
    "\n",
    "print(f'Nimiöidyn Training-joukon ensimmäinen jälki')\n",
    "print(f'  koko:{training_sequences_labeled[0][0].shape}')\n",
    "print(f'  luokka:{training_sequences_labeled[1][0]}')\n",
    "\n",
    "print(f'Nimiöidyn Validation-joukon ensimmäinen jälki')\n",
    "print(f'  koko:{validation_sequences_labeled[0][0].shape}')\n",
    "print(f'  luokka:{validation_sequences_labeled[1][0]}')\n",
    "\n",
    "print(f'Nimiöidyn Attack-joukon ensimmäinen jälki')\n",
    "print(f'  koko:{attack_sequences_labeled[0][0].shape}')\n",
    "print(f'  luokka:{attack_sequences_labeled[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yhdistetäänpä vielä Validation- ja Attack-joukot yhdeksi testijoukoksi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nimiöidyn testijoukon\n",
      "  sekvenssien määrä:5118\n",
      "  nimiöintien määrä:5118\n"
     ]
    }
   ],
   "source": [
    "test_sequences = validation_sequences_labeled[0]+attack_sequences_labeled[0]\n",
    "test_labels = validation_sequences_labeled[1]+attack_sequences_labeled[1]\n",
    "test_sequences_labeled = [test_sequences,test_labels]\n",
    "print(f'Nimiöidyn testijoukon')\n",
    "print(f'  sekvenssien määrä:{len(test_sequences_labeled[0])}')\n",
    "print(f'  nimiöintien määrä:{len(test_sequences_labeled[1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data tensoreiksi\n",
    "\n",
    "Viimeinen tehtävä asia on datojen muuntaminen helposti hyödynnettävään muotoon. Koska tavoitteena on käyttää [PyTorchin LSTM-implementaatiota](https://pytorch.org/docs/0.4.1/nn.html#lstm), on datan oltava valmiiksi sopivan pituisissa sekvensseissä. Tämän vuoksi datat pitää vielä muuntaa sellaiseen muotoon, jossa kustakin jäljestä eli sekvenssistä muodostetaan ikäänkuin liukuvan ikkunan tapaan määrätyn pituisia limittäisiä alisekvenssejä. Samalla datat muunnetaan ja tallennetaan [PyTorch-tensoreiksi](https://pytorch.org/docs/0.4.1/tensors.html). Tässä kaikessa on edelleenkin silti noudatettava huolellisuutta siinä, ettei alisekvenssejä muodosteta jälkien välille.\n",
    "\n",
    "Aloitetaan jälleen yksinkertaisesti yhdellä sekvenssillä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0]]), 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_labeled = [training_sequences_labeled[0][0],training_sequences_labeled[1][0]]\n",
    "sequence_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tässä vaiheessa voidaan jo sopia, että sovelias sekvenssin pituus on kolme järjestelmäkutsua, sillä limittäinen alisekvensöinti moninkertaistaa datan alisekvenssin pituudella. Tästä seuraa nopeasti muistiongelmia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alisekvenssöidyn sekvenssin\n",
      "  sekvenssien muoto:(1983, 3, 175)\n",
      "  nimiöiden muoto:(1983,)\n"
     ]
    }
   ],
   "source": [
    "subsequence_length = 3\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(sequence_labeled[0])-subsequence_length):\n",
    "    x.append(sequence_labeled[0][i:i+subsequence_length])\n",
    "    y.append(1)\n",
    "\n",
    "print('Alisekvenssöidyn sekvenssin')\n",
    "print(f'  sekvenssien muoto:{np.array(x).shape}')\n",
    "print(f'  nimiöiden muoto:{np.array(y).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sovelletaanpa tätä sitten koko koulutusjoukkoon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alisekvenssöidyn koulutusdatan\n",
      "  sekvenssien muoto:(305578, 3, 175)\n",
      "  nimiöiden muoto:(305578,)\n",
      "  luokan 1 osuus:305578/305578\n",
      "  luokan 0 osuus:0/305578\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(training_sequences_labeled[0])):\n",
    "    training_sequence = training_sequences_labeled[0][i]\n",
    "    training_label = training_sequences_labeled[1][i]\n",
    "    for j in range(0, len(training_sequence)-subsequence_length):\n",
    "        x_train.append(training_sequence[j:j+subsequence_length])\n",
    "        y_train.append(training_label)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print('Alisekvenssöidyn koulutusdatan')\n",
    "print(f'  sekvenssien muoto:{x_train.shape}')\n",
    "print(f'  nimiöiden muoto:{y_train.shape}')\n",
    "print(f'  luokan 1 osuus:{len(y_train[y_train==1])}/{len(y_train)}')\n",
    "print(f'  luokan 0 osuus:{len(y_train[y_train==0])}/{len(y_train)}')\n",
    "\n",
    "np.save(os.path.join(ADFA_LD_DIR,'x_train'),x_train)\n",
    "np.save(os.path.join(ADFA_LD_DIR,'y_train'),y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tehdään sama myös testijoukolle. Testijoukko on sen verran suurempi kokonaisuus, että lopullinen joukko on rakennettava osissa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alisekvenssöidyn testidatan\n",
      "  sekvenssien muoto:(2424119, 3, 175)\n",
      "  nimiöiden muoto:(2424119,)\n",
      "  luokan 1 osuus:2108969/2424119\n",
      "  luokan 0 osuus:315150/2424119\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(len(test_sequences_labeled[0])):\n",
    "    test_sequence = test_sequences_labeled[0][i]\n",
    "    test_label = test_sequences_labeled[1][i]\n",
    "    for j in range(0, len(test_sequence)-subsequence_length):\n",
    "        x_test.append(test_sequence[j:j+subsequence_length])\n",
    "        y_test.append(test_label)\n",
    "        \n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print('Alisekvenssöidyn testidatan')\n",
    "print(f'  sekvenssien muoto:{x_test.shape}')\n",
    "print(f'  nimiöiden muoto:{y_test.shape}')\n",
    "print(f'  luokan 1 osuus:{len(y_test[y_test==1])}/{len(y_test)}')\n",
    "print(f'  luokan 0 osuus:{len(y_test[y_test==0])}/{len(y_test)}')\n",
    "\n",
    "np.save(os.path.join(ADFA_LD_DIR,'x_test'),x_test)\n",
    "np.save(os.path.join(ADFA_LD_DIR,'y_test'),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mallin rakentaminen\n",
    "\n",
    "Kun data on kutakuinkin hyödynnettävässä muodossa, on aika siirtyä mallin pariin. Malli rakennetaan PyTorch-kehyksellä hyödyntäen `fastai`-opetuskirjastoa. Tärkeimmässä roolissa tulee olemaan oikeanlaisen `Dataset`-luokan rakentaminen, joka tarjoaa datan PyTorchin LSTM-implementaation vaatimassa muodossa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset-luokka\n",
    "\n",
    "Koska mallinnuksen keskipiisteessä on pohjimmiltaan ohjaamattoman oppimisen ongelma, jossa tavoitteena on oppia perustila poikkeamien erottamiseksi, koulutetaan malli erikseen sitä varten tarkoitetulla Training-joukolla. Opittua mallia arvioidaan käyttämällä Attack- ja Validation-joukkojen datoista muodostettua testijoukon dataa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "ADFA_LD_DIR = os.path.join(os.getcwd(),'datasets','ADFA-LD')\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = np.load(os.path.join(ADFA_LD_DIR, 'x_train.npy'))\n",
    "        self.y = np.load(os.path.join(ADFA_LD_DIR, 'y_train.npy'))\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.x[idx]), torch.Tensor([self.y[idx]])\n",
    "        \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x = np.load(os.path.join(ADFA_LD_DIR, 'x_test.npy'))\n",
    "        self.y = np.load(os.path.join(ADFA_LD_DIR, 'y_test.npy'))\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.x[idx]), torch.Tensor([self.y[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-luokka\n",
    "\n",
    "Seuraavaksi luodaan haluttu pinottu LSTM-malli. Samalla määritellään käytetty RMSE-virhefunktio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.LSTM(input_size=175,hidden_size=3,num_layers=2,batch_first=True,dropout=0.5).cuda()\n",
    "mse = lambda pred,true: nn.MSELoss()(pred[0][:,-1,-1].unsqueeze(-1),true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seuraavaksi määritellään sekä optimointialgoritmi että `fastai`-kouluttaja sen vaatimine `Dataset`-luokkien wrappereineen mallille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=3), HTML(value='0.00% [0/3 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 02:44\n",
      "epoch  train loss  valid loss\n",
      "0      0.000024    0.128745    (00:53)\n",
      "1      0.000024    0.128745    (00:53)\n",
      "2      0.000024    0.128745    (00:57)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fastai.data import DataBunch\n",
    "from fastai.basic_train import Learner\n",
    "from torch.optim import RMSprop\n",
    "%matplotlib inline\n",
    "\n",
    "train_set = TrainDataset()\n",
    "test_set = TestDataset()\n",
    "data_bunch = DataBunch.create(train_ds=train_set, valid_ds=test_set, num_workers=0)\n",
    "learner = Learner(data=data_bunch,model=model, opt_fn=RMSprop, loss_fn=mse)\n",
    "result = learner.fit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Katsotaanpa seuraavaksi, mitä meidän mallimme oikeastaan oppi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "test_loader = DataLoader(test_set,batch_size=256)\n",
    "for batch in test_loader:\n",
    "    batch_preds = model(batch[0].cuda())\n",
    "    batch_trues = batch[1]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951, 0.9951,\n",
       "        0.9951, 0.9951, 0.9951, 0.9951],\n",
       "       device='cuda:0', grad_fn=<CloneBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_preds[0][:,-1,-1].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Sisällysluettelo",
   "title_sidebar": "Sisällysluettelo",
   "toc_cell": true,
   "toc_position": {
    "height": "1158px",
    "left": "278px",
    "top": "111.133px",
    "width": "236px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
